[
  {
    "path": "posts/2022-04-25-gitlab-cicd-to-enforce-test-coverage/",
    "title": "GitLab CI/CD to Enforce Test Coverage",
    "description": "How to automatically block your pipeline when test coverage is below a minimum requirement.",
    "author": [
      {
        "name": "kylechung",
        "url": {}
      }
    ],
    "date": "2022-04-25",
    "categories": [],
    "contents": "\nGitLab CI/CD is a very powerful tool.\nThe idea here is that I would like to use a pipeline job to block, say, a release, from being pushed by checking if the unittest coverage is at least above 90% or something. That sounds very straightforwad, but yet it is surprisingly not that simple to set up.\nThere is a related feature for GitLab called “Coverage-Check” under the general settings of “Merge request approvals.” It allows you to set review approval rule when the coverage drops. To be honest that doesn’t sound very useful to me.\nAnyway, I’ve researched and experimented a bit on how I can block a CI pipeline by checking coverage, and here is a solution.\nSolution\nThe idea is to use GitLab API to retrieve the coverage data from a previously run job inside another CI job, and do the math and raise whenever necessary.\nPre-requsite\nAccess token\nWe need a token to make a call from the CI runner. For free-tier we will use personal-access token while for company subscription you should prefer either a project or a group level access token. In either case, we will configure it as a protected and masked CI/CD variable. I will use the name BOT_TOKEN for it.\nCoverage parsing\nGitLab does not magically know your test coverage without you explicitly tell it how to find a value. This can be done by either an explicit cofiguration on the .gitlab-ci.yml or use the GUI to set it up. Before this is done, the API response object will have the coverage with a null value.\nThe Pipeline API\nTo test the API, we can make a call to check the pipeline status of a particular branch:\nCI_PROJECT_ID=35619033  # this is my demo project\nCI_API_V4_URL=https://gitlab.com/api/v4\nCI_COMMIT_TAG=master\n\ncurl -s --header \"PRIVATE-TOKEN: ${BOT_TOKEN}\" \\\n        \"${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/pipelines?ref=${CI_COMMIT_TAG}&status=success\" | jq\nby using jq we can get the value of this particular pipeline-id, and make another call to get the coverage value of a testing job in the given pipeline:\nPIPELINE_ID=`curl -s --header \"PRIVATE-TOKEN: ${BOT_TOKEN}\" \\\n  \"${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/pipelines?ref=${CI_COMMIT_TAG}&status=success\" \\\n  | jq \".[0].id\"`\n\n# assume our test job is named \"unittest\"\nCURRENT_COVERAGE=`curl -s curl -s --header \"PRIVATE-TOKEN: ${BOT_TOKEN}\" \\\n  \"${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/pipelines/${PIPELINE_ID}/jobs\" \\\n  | jq '.[] | select( .name == \"unittest\" ) | .coverage // 0'`\n\necho $CURRENT_COVERAGE\nDEMO\nI’ve setup a demo repository to showcase the pipeline:\ntest-coverage-ci\nwhere a complete .gitlab-ci.yml can be found and the pipeline in action.\nDo check it out if you are interested!\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-25T08:46:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-23-bye-bye-time-capsule/",
    "title": "Bye Bye, Time Capsule",
    "description": "After a surprisingly durable 8 years of serice, time to let go.",
    "author": [
      {
        "name": "kylechung",
        "url": {}
      }
    ],
    "date": "2022-04-23",
    "categories": [],
    "contents": "\n\n\n\nI didn’t thought it could last that long. It was bought in around year 2013.\nWhile the access point is working just fine even before the teardown, the harddrive does start having random failure 2 years back despite nothing really went missing. Most importantly, I’m no longer patient with the read/write speed of such an old tech. I don’t have any HDD other than this 2TB Seagate Barracuda. It took me 4+ hours to wipe out the disk before the disposal.\nThe fork? Yep I actually use a fork to help me tear it apart. Along with a can opener.\nThat was fun.\n\n\n\n",
    "preview": "posts/2022-04-23-bye-bye-time-capsule/airport_timecapsule.jpg",
    "last_modified": "2022-04-23T07:08:46+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-16-my-new-macbook-pro-setup/",
    "title": "My 2021 Macbook Pro Setup",
    "description": "Everything I Want for a Developer's Environment",
    "author": [
      {
        "name": "kylechung",
        "url": {}
      }
    ],
    "date": "2022-04-16",
    "categories": [],
    "contents": "\nAfter 5 years (2016-2021) of wrong doings such as the useless touch\nbar, troublesome keybord design, among many others, Apple has finally\ncome back to have a decent Macbook Pro model, along with its amazing M1\nchip.\nSo here I’m back, too. ;)\nThis article is a simple documentation + murmurs on what I need\n(want?) to setup my dev environment on a new machine. They are actually\nmore or less OS-agnostic, but this time due to the changing architecture\nto ARM, some research has to be done to make sure everything is running\nas expected.\nPackage Manager\nHomebrew seems to be the only one I\nneed for macOS package management.\nTerminal & IDE\noh-my-zsh\nMacOS now ships with zsh by default. Personally I feel oh-my-zsh is\njust good enough for me out-of-the-box.\nmacos-terminal-themes\nMacOS’s default Terminal.app has quietly evolved a lot during the\npast decade. I used to prefer iTerm2 but now I think I only need\nTerminal.app. The only thing I need is to make it colorful.\nVS\nCode\nOnce being a Vim enthusiastic, now I rely more on VS Code for my\nday-to-day coding and writing. It is actually because I need a\ncross-platform editor to reduce as much as possible the friction while I\nneed to switch between different machines. I used to work in an\nenvironment where only Windows is available. (And, of course, you don’t\nhave the admin right.) Using Vim on Windows is just not pleasant. And\nthat’s where I met VS Code, and gradually start to enjoy it.\nI think nowadays it is just one of the most popular and also very\nuseful IDE. Well I still use Vim, but just not as much as I used to.\nSome must-have extensions for me:\nPlantUML\nMarkdown\nAll in One\nCSV\nto Table\nPython\nR\nPython\npyenv & pyenv-virtualenv\nThe must-have Python versioning and virtualenv framework. I’ve been\nusing it for years and never switch to any other alternatives.\nOne caveat: if I am on a Windows machine, I may need to fallback to\nconda since the pyenv experience on Windows is\nnot that pleasant. Well I usually just use WSL to bypass all the hassles\nI may have if I were to work on a Windows machine. But that is not\nalways feasible, say, if you are working for a bank.\nR\nradian\nA very nice console to just replace the default one.\nI feel that I shall mention RStudio as well. It is the go-to IDE\nfor R with no realistic competitors for a decade. But I’m relying on it\nless and less in the recent years even while I focus on analytical\nworks. I think it has something to do with RStudio’s ambition to be more\nthan it needs to be. The IDE is just feeding too many features to me\nthat I don’t need. I’d rather have a simple REPL with a nicely colored\nconsole and auto completion to get the job done.\nYep. I’m also never a fan of the .Rproj thing.\nNow if I need interactive coding in R, I’ll just use VS Code with\nradian as its terminal.\nI still use RStudio, but very specifically for editing complicated\nRmarkdown files only. To me RStudio is now just a dedicated\nRmarkdown IDE. I may eventually use VS Code extentions to\nreplace it anyway.\nrenv\nA nice package versioning tool that I found I should use it as much\nas I can.\nThere is no Python virtualenv counterpart in the R\nworld. Partly because it is not urgently needed. But still, if you use R\nextensively enough you are going to bump into the version management\ntrouble. Tool such as renv handles only package version and\nnot R itself. But it is a very good start.\nJava\nI’m not a Java guy at all. But we will need from time to time the\nJava runtime for quite some applications. And sometimes JRE is not\nenough so why not just install JDK once and for all.\nbrew install openjdk\nsudo ln -sfn /opt/homebrew/opt/openjdk/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk.jdk\nSpark\nI may need to figure out the best way to install local Spark instance\nwith M1 since the newest Spark still relies on a relatively older\nversion of Java. Ideally I want the M1 machine to run on only the newest\nJava which does not require a Rosetta layer.\nI may come up with another post on doing this if I managed to have a\nway out. Hopefully not jEnv. :)\nVirtualization &\nContainerization\nDocker\nAn increasingly debatable choice of containerization. No doubt it is\nstill the most popular tool in the market. Personally I found it may not\nbe too difficult to switch to another container tech, since they are all\ntrying to follow the existing workflow (notably, OCI) that has been originally\nestablished by Docker’s dev community, so that users can seamlessly\nadopt them.\nMultipass\nA light-weight VM managmenet command line tool specific to Ubuntu.\nSince I usually only need Ubuntu when it comes to virtualization (with\none exception coming latter), so this is handy.\nUTM\nVirtualBox is out. It doesn’t support ARM.\nThat brings us UTM to the attention. UTM can do both virualization\nand emulation. the latter is required when your host OS has a\ndifferent architecture than the guest OS. This can be the case\nespecially when we have a Macbook Pro with M1 chip, which is ARM\narchitecture.\nWhile emulation is going to have overhead since there is additional\nlayers of translation. I’m using UTM only to install Kali Linux, which supports ARM\narchitecture.\nOne thing to note is that after installation it won’t boot but will\nstuck at the UEFI shell. This is found on\nQEMU 6.2 ARM Virtual Machine with\nkali-linux-2022.1 image.\nA solution has been discussed in this thread. In\nshort, we need to cd to fs0 in the UEFI shell (by typing\nfs0: and hit enter) and create/edit a file called\nstartup.nsh (we can use edit <filename>\nto open a built-in editor). Insert the following line in the file:\nfs0:\\efi\\kali\\grubaa64.efi\nand reboot.\nNow to enable clipboard and directory sharing we need to install the\nfollowing additional packages in Kali:\nsudo apt update\nsudo apt install spice-vdagent spice-webdavd\nInfrastructure\nTerraform\nA useful and widely adopted infrastructure-as-code framework. I’ve\nbeen working extensively in the past 1 year with Terraform to manage\ndata infra stack in AWS.\nbrew install terraform\nLocalStack\nA very interesting project to deploy AWS components locally (in just\none container!) for testing purpose. Though it seems that it is running\nmuch slower on M1 than on the previous x86_64 Macbook.\nminikube\nLocal Kubernetes playground.\nbrew install minikube\naws-vault\nA very useful AWS credential management tool, especially convenient\nwhen you have multiple accounts or multiple IAM roles to assume in your\nworkflow.\nbrew install --cask aws-vault\nMiscellaneous\njq\nA handy command line json parser. Very useful when we need to\nfrequently deal with json lines.\nbrew install jq\nGraphviz\nThis will be required for some plotting utilities (such as\nPlantUML).\nbrew install graphviz\nPandoc\nThe core dependency for Rmarkdown.\nbrew install pandoc\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-17T12:04:39+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-12-wsl-ssh-server-setup/",
    "title": "WSL SSH Server Setup",
    "description": "How to setup SSH server on your WSL 2 Ubuntu for remote-logins.",
    "author": [
      {
        "name": "kylechung",
        "url": {}
      }
    ],
    "date": "2022-04-12",
    "categories": [],
    "contents": "\nThis is to log down my new setup of a Windows 11 desktop with WSL 2 (Ubuntu 20.04). The goal is to be able to ssh to the WSL from my other computers in the local network. There are indeed multiple ways of doing so, this time I decided to make it as simple as possble.\nRun a powershell with admin right, check the installation status of both the ssh client and server:\nGet-WindowsCapability -Online | ? Name -like 'OpenSSH*'\nHighly likely the client is installed by default while the server is not.\nNow install the server:\nAdd-WindowsCapability -Online -Name OpenSSH.Server~~~~0.0.1.0\nSet it to start automatically in the future:\nSet-Service -Name sshd -StartupType 'Automatic'\nAnd also start it right now:\nStart-Service sshd\nNow we can test if the connection work by something like:\nssh k9@192.168.1.1\nfrom another computer.\nIf it works it will give us a Windows shell. We can run wsl from there to prompt the Ubuntu bash. Or even lazier, by setting the default ssh login shell to the Ubuntu bash:\nNew-ItemProperty -Path \"HKLM:\\SOFTWARE\\OpenSSH\" -Name DefaultShell -Value \"C:\\WINDOWS\\System32\\bash.exe\" -PropertyType String -Force\nThis approach does not require setting up the ssh server on Ubuntu since it is the Windows host machine that is handling the SSH connection.\nThat’s neat.\nWhy Windows 11? Because now it by default supports WSL with GPU passthrough. And I have a RTX 2080Ti now ready for things beyond gaming. :)\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-12T08:33:07+00:00",
    "input_file": {}
  }
]
